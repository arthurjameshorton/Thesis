\chapter{Physics Object Reconstruction}
\label{Reco}

\section{Electron/Photon}
\label{EMReco}
The reconstruction of electrons and photons with the ATLAS detector involves measurements by both the electromagnetic calorimeter and the inner detector.  
The process begins with a list of clusters found using a sliding window with a size equal to 3 x 5 cells ($\eta$ x $\phi$) in the second layer of the EM calorimeter.  
Tracks are also fit in the inner detector, a process which begins by clustering together neighboring cell hits in each layer of the tracking system.  
Track seeds are then created using sets of three of these clusters and assuming a perfect helical trajectory in a uniform magnetic field.  
Track seeds can be rejected based on their reconstructed momentum, on impact parameter (how close they come to the interaction point), and by not being near enough to any additional clusters~\cite{Aaboud:2017all}.  
The electron and photon reconstruction algorithms used a modified version of the list of reconstructed tracks, where tracks containing only hits in the TRT being simply copied over and tracks with silicon hits are refit to account for the potentially large radiative energy loss that electrons can experience during their flight~\cite{ATLAS-CONF-2012-047}.  
Tracks become associated with a calorimeter cluster if they are close enough in $\eta$-$\phi$ (0.05 x 0.05 with Si, 0.35 x 0.02 without) and pass some quality criteria.  
Clusters with tracks are candidates for either electrons or photons that have converted to an electron-positron pair, where either both or only one track is reconstructed.  

At this stage clusters are expanded to 3 x 7 (5 x 5) in the barrel (endcap).  
Clusters with two tracks without pixel layer hits or with no single track having more than 4 Si hits are labeled as photon candidates, while clusters with single tracks including pixel hits are labeled as electron candidates.  
The energy of these larger clusters is used as the input energy of the object for calibration, while the $\eta$ and $\phi$ are taken from the track(s) (if present) or the cluster (with no tracks).  

\section{Muons}
\label{Muons}

Muons are reconstructed using information from both the muon spectrometer and the inner detector.  
Muon reconstruction begins by creating station by station muon track segments which are then fit into a combined track.  
The fit takes into account the magnetic field from the toroid magnets and a detailed description of the material density throughout the detector.  
These spectrometer-only muon tracks are then propagated through the calorimeter (again taking the energy the muons deposit into account) back into the inner detector.  
Here they are are combined with tracks left by the muon in the tracking detector that have been reconstructed using the regular all-purpose track reconstruction algorithm.  

\section{Jets}
\label{jets}

A result of colour confinement (see Sec.~\ref{SM}) is that single particles with colour charge cannot be observed.  
This does not actually eliminate collisions where a large amount of energy is transfered to a single quark or gluon.  
When these types of collision do occur (they are actually the most commonly occurring type of collisions in a p-p collider) what is seen is a large `spray' of hadrons all traveling along roughly the same path in which the original single particle was moving.  
This spray is created iteratively by quarks radiating gluons, which create quark/anti-quark pairs, which subsequently radiate additional gluons, a process known as parton showering.  
When the amount of energy per gluon drops below the pair creation threshold a second stage known as hadronization takes over, where these secondary coloured particles combine into colour neutral particles.  
Collectively these two stages are known as quark or gluon fragmentation.  

\begin{figure}[!ht]
  \begin{center}
    \scalebox{0.4}{
      \includegraphics{plots/Chap3/PartonShower.ps}
    }
  \end{center}
  \caption[Parton showering diagram]
  {\small Example showing the progression of a parton shower.  }
\end{figure}

It is now worth going into slightly more detail as to why QCD behaves so strangely compared to QED, and pointing out a few additional consequences.  
In quantum field theories calculations are done using series expansions.  
Each term in the series is scaled by the coupling constant of the force in question raised to some power.  
In the case of QED the coupling constant is such that terms with the coupling constant to higher orders are quite small and at some point can be ignored.  
These smaller and smaller terms can be considered corrections to the larger terms, making QED what is known as a perturbative theory.  
There is an energy dependence to the coupling constant, where it becomes lower at lower energies as a result of the bare charge of particles being partially screened by a cloud of virtual particles.  

With QCD this screening goes the other way, with the apparent charge of quarks growing at lower energies.  
This is because along with the charge screening provided by light quarks there is a larger anti-screening effect provided by the gluons (as they also carry colour charge).  
This effect is such that at low enough energies the coupling constant becomes larger than one, making QCD non-perturbative and leaving only phenomenological models to simulate the behaviour of QCD.  
This means that for the simulated samples that will be used there will be both a strictly QCD portion of the showers (parton showering) and a phenomenological portion (hadronization).  

As was mentioned in Sec.~\ref{Had} the interactions between hadrons and matter tend to lead to wide and deep showers that are subject to large fluctuation.  
The large number of hadrons moving in the same direction combined with this showering profile means that accurately measuring the properties of these sprays in the calorimeter can be challenging.  
The strategy that is generally used is two staged.  
First, individual particle candidates are constructed followed by a second stage where these particle candidates are combined with nearby particles into groups that are known as jets.  
Multiple options are available for each stage.  

ATLAS has previously used calorimeter towers (stacks of cells in the calorimeter pointing back to the centre of the inner detector) and `TopoTowers' (towers with additional noise suppression) as inputs to jet finding algorithms, but they aren't necessarily a good representation of a single particle.  
Tracks in the inner detector can also be used to define jets, although using only tracks ignores all neutral particle information obtained by the calorimeter.  
The most commonly used input to jet finding algorithms in ATLAS are topological clusters of calorimeter cells.  
 
\subsection{Topological Clusters}

\begin{figure}[!ht]
  \begin{center}
    \scalebox{0.4}{
      \includegraphics{plots/Chap3/TopoClustering.ps}
    }
  \end{center}
  \caption[Topoclustering diagram]
  {\small Example of the 4-2-0 topocluster algorithm showing how cells passing the different thresholds are grouped together.  }
\end{figure}

In the context of high energy physics detectors topological (topo) clustering is an algorithm where individual calorimeter cells are grouped together based on how significant the energy deposited within a given cells is relative to its neighbours and to the expected noise.  
Topo clusters can have a wide variety of three dimensional shapes, which allows them to include a large fraction of the energy deposited by incoming particles while ignoring much of the noise.  

Topo clustering begins by determining the significance of the energy deposited within each cell, which is defined as the absolute value of the measured energy divided by the average expected noise for that cell.  
All cells above some predetermined threshold, $t_{\mathrm{seed}}$, are then put into a list proto-clusters.  
Next, cells with an energy above a second threshold, $t_{\mathrm{neighbor}}$, and which are `neighbors' to a proto-cluster are added to that proto-cluster.  
In this case neighbors consist of the eight nearest neighbors and next to nearest neighbors in the same layer of the calorimeter as the seed cell, as well as all cells in adjacent layers which overlap or partially overlap with any of these nine cells.  
Next-to-nearest neighbours are then checked until there are no longer any neighbor cells above $t_{\mathrm{neighbor}}$.  
The final stage of cluster building involves adding a single final layer around each proto-cluster of all neighboring cells above some third threshold, $t_{\mathrm{cell}}$~\cite{1603.02934}.  
The thresholds used in topoclustering are usually reported as $t_{\mathrm{seed}}-t_{\mathrm{neighbor}}-t_{\mathrm{cell}}$; ATLAS uses a 4-2-0 clustering scheme.  
4-3-0 topo clusters are also used in ATLAS to reconstruct low $p_T$ electrons, but they will not be used in this thesis.   

After all clusters have been fully formed there is an additional stage where clusters are split.  
This begins by looking for local maxima within a given cluster, which are defined as a cell having an energy above 500 MeV with at least four neighbours, none of which have a higher energy than the cell in question.  
The cells which merged the two local maxima are have their energy split between the two subclusters, where the energy going into each of the two subclusters is determined using the relative energy of the subclusters as well as the distance between the splitting cell and the two local maxima.  
 
While topo clusters do a relatively good job of representing the visible energy deposited in the detector by a single particle they are not perfect.  
Clustering may leave some visible energy outside of the bounds of a cluster, energy may be deposited in dead material, or the energy may simply be mis-measured as the response to EM energy of the ATLAS detector (e) is not equal tot he response of hadronic energy deposits ($h$).  
These are the factors that motivate the second collection of clusters used by ATLAS.  
This second collection begins with the original (EM scale) clusters and applies a series of cell-by-cells weights base on energy density in an attempt to correct these problems at the cluster level.  
The weights are one for EM-like deposits (large density) and greater than one for hadron-like deposits (small density).  
This calibration scheme is known as local hadronic cell weighting, or the LC scale.  
The applied corrections depend on energy-based moments of the cluster, the depth and density of the cluster is used for EM/Had identification for example.  
The correction also depends on the physical location of the cluster which is used to estimate the energy lost in dead material.  
This calibration is Monte Carlo based.  

\subsection{Jet Finding}

\begin{figure}[!ht]
 \centering
 \begin{subfigure}{.5\textwidth}
  \centering
  \scalebox{0.3}{
   \includegraphics{plots/Chap3/cone-fig1.ps}
  }
  \caption{Infrared radiation merging jets.}
 \end{subfigure}%
 \begin{subfigure}{.5\textwidth}
  \centering
  \scalebox{0.3}{
   \includegraphics{plots/Chap3/cone-fig2.ps}
  }
  \caption{Collinear radiation changing jet topology.}
 \end{subfigure}
 \begin{subfigure}{.5\textwidth}
  \centering
  \scalebox{0.7}{
   \includegraphics{plots/Chap3/COSafe.ps}
  }
  \caption{Jet existence depending on collinear radiation.}
 \end{subfigure}
 \caption[Effect of radiation on jet building.]
  {A few examples of how soft infrared/collinear radiation can effect the reconstructed jet topology of an event.  In example $a$ soft infrared radiation causes two potential jets to merge into a single jet.  In example $b$ collinear radiation causes the central particle to be lower down the list of jet seeds, changing the jet topology.  Example $c$ shows how the presence of collinear radiation has the possibility to lower the reconstructed energy below the jet seed threshold.  Figures from ~\cite{Blazey:2000qt}. }
 \label{Fig:IRCoSafety}
\end{figure}

In order to meaningfully compare experimental results and fixed order QCD calculations jet algorithms must behave in a way that follows certain criteria~\cite{Blazey:2000qt}.  
These criteria are infrared and collinear safety, which mean that the reconstruction should be insensitive to soft and collinear radiation, respectively.  
Without these criteria the jet topology in simulated events would be very dependent on how the low $p_{\mathrm T}$/small angle singularities in the parton splitting functions are handled, making it difficult to compare theory to experiment.  
A family of jet finding algorithms used in ATLAS that satisfies these criteria is the $k_t$ family~\cite{Cacciari:2008gp}.  
Specifically $k_t$ jets, Cambridge/Aachen jets, and the most commonly used type, anti-$k_t$ jets.  
Objects that are used as inputs to these algorithms by ATLAS include tracks, truth particles\footnote{In ATLAS truth particles are simulated particles which are stable, which is defined as having a lifetime $c\tau _{\mathrm 0}$ greater than 10 mm.  The list of truth particles does not include particles which are the result of showering in the detector, and for jet building purposes muons and neutrinos are also not included~\cite{ATL-PHYS-PUB-2015-013}.}  (in Monte Carlo samples), clusters, etc.  
These algorithms all begin by constructing a list of proto jets, which consists of four vectors representing all of the inputs at the desired scale (e.g. EM or LC clusters for calorimeter jets).  
Next a `distance' between every pair of jets is calculated, which defined as:

\begin{equation}
  d_{ij}=min\left(p_{\mathrm T,i}^{2n}, p_{\mathrm T,j}^{2n}\right)\frac{\Delta_{ij}^2}{R^2}, 
\end{equation}
\noindent
where $\Delta_{ij}$ is defined as 

\begin{equation}
  \Delta_{ij} = \sqrt{ \left(\phi_i-\phi_j\right)^2+\left(\eta_i-\eta_j\right)^2}
\end{equation}
\noindent
and $R$ is a tunable size parameter, and the parameter $n$ determines the behaviour of the algorithm, with $n$=1,0,-1 being the $k_t$, Cambridge/Aachen, and anti-$k_t$ algorithms respectively.  
Additionally for each pseudo jet a distance to the beam pipe is calculated using:

\begin{equation}
  d_{iB} = p_{\mathrm T,i}^{2n}.
\end{equation}  
\noindent
The jet building is then performed by finding the smallest distance parameter.  
If it corresponds to a proto jet/beam pipe distance that proto jet is promoted to being a full jet, while if it is a proto jet pair these are removed from the list and combined into a new proto jet which is added to the list.  
While different four-momentum combination schemes exist ($p_{\mathrm T}$ weighted, $p_{\mathrm T}^2$ weighted) ATLAS uses a simple addition of the four-vectors of the proto jets using the FastJet implementation~\cite{Cacciari:2011ma}.  

While the $k_t$, Cambridge/Aachen, and anti-$k_t$ algorithms are all used in ATLAS each they are all used for different purposes base on their individual strengths and weaknesses.  
One large difference between the $k_t$ and the anti-$k_t$ algorithms is that the $k_t$ algorithm begins with the lowest $p_{\mathrm T}$ proto jets while the anti-$k_t$ begins with larger $p_{\mathrm T}$ proto jets.  
This means that proto jets are quite stable in location as they grow in the anti-$k_t$ algorithm (which tends to lead to quite circular jets) this is not the case for $k_t$ jets, which tend to have a wide variety of final jet shapes (see Fig.~\ref{Fig:ExampleJets}).  
This $k_t$ growth can lead to some pathological cases where the jet grows well beyond what one would intuitively call a jet.  

\begin{figure}[!ht]
 \centering
 \begin{subfigure}{.5\textwidth}
  \centering
  \scalebox{0.25}{
   \includegraphics{plots/Chap3/herwig-parton-level-ev-antikt-R1.0-ghosted4root.ps}
  }
  \caption{Anti-$k_t$ jets using R=1.0.}
 \end{subfigure}%
 \begin{subfigure}{.5\textwidth}
  \centering
  \scalebox{0.25}{
   \includegraphics{plots/Chap3/herwig-parton-level-ev-kt-R1.0-ghosted4root.ps}
  }
  \caption{$k_t$ jets using R=1.0.}
 \end{subfigure}
 \caption[Comparing differnet jet building algorithms.]
  {Outputs of both the anti-$k_t$ and $k_t$ algorithms when run over the same event, where both have been run using size parameter R=1.0.  Truth particles from an event generate with HERWIG have been used as inputs.  Figure from ~\cite{Cacciari:2008gp}. }
 \label{Fig:ExampleJets}
\end{figure}



\section{Missing Transverse Energy}

While large multipurpose detectors like ATLAS do a good job of detecting a large range of particles they do not and cannot measure 100\% of the energy of every particle produced in every collision.  
Some of this missed energy is from particles interacting with the detector and having a response lower than one.  
Sometimes the more interesting energy that is undetected comes from particles that do not interact with the detector at all (eg. neutrinos).  
It is not always straightforward to measure how much energy the calorimeter did not detect.  
Fortunately in a p-p collider all of the initial momentum of the collision is along the beam line, with the exception of a small (effectively negligible) amount of transverse momentum within the protons themselves.  
Using the conservation of momentum one can use an imbalance in momentum along any given axis in the transverse plane and interpret the missing energy that would balance the momentum as a measurement itself.  
This quantity is known as the \gls{MET} or $E_{\mathrm T}^{miss}$.  


The MET, like jets, can be constructed using a number of different inputs at various scales.  
For many analyses in ATLAS the most appropriate MET to use is one where all physics objects are used at their fully calibrated scales.  
This is done by starting with some base collection (EM clusters, LCW clusters, tracks, etc.) then adding physics objects while removing overlapping base objects to avoid double counting.  
The final MET is calculated by taking the negative vector sum of the transverse momentum of the remaining base objects and all physics objects.  
The work described in this thesis uses topo cluster based METs with only photons, electrons, and muons being replaced by the fully calibrated objects.  




